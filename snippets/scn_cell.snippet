class SCNCell(nn.Module):
    r"""Custom Cell for Implementing Semantic Compositional Networks

    Arguments
        input_size (int): size of input
        hidden_size (int): size of embedding
        semantic_size (int): size of semantic
        factor_size (int): size of factor
        bias (boolean, optional): use bias?
    """

    def __init__(self, input_size, hidden_size, semantic_size, factor_size, bias=True):
        super(SCNCell, self).__init__()

        self.factor_size = factor_size
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.semantic_size = semantic_size

        self.weight_ia = nn.Parameter(
            torch.Tensor(input_size, 4 * factor_size))
        self.weight_ib = nn.Parameter(
            torch.Tensor(semantic_size, 4 * factor_size))
        self.weight_ic = nn.Parameter(
            torch.Tensor(hidden_size, 4 * factor_size))

        self.weight_ha = nn.Parameter(
            torch.Tensor(hidden_size, 4 * factor_size))
        self.weight_hb = nn.Parameter(
            torch.Tensor(semantic_size, 4 * factor_size))
        self.weight_hc = nn.Parameter(
            torch.Tensor(hidden_size, 4 * factor_size))

        if bias:
            self.bias_ih = nn.Parameter(torch.Tensor(4 * hidden_size))
            self.bias_hh = nn.Parameter(torch.Tensor(4 * hidden_size))
        else:
            self.register_parameter('bias_ih', None)
            self.register_parameter('bias_hh', None)

        self.reset_parameters()

    def forward(self, wemb_input, semantic_input, hx=None):
        self.check_forward_input(wemb_input)

        [ia_i, ia_f, ia_o, ia_c] = split_tensor2d(
            self.weight_ia, self.factor_size)
        [ib_i, ib_f, ib_o, ib_c] = split_tensor2d(
            self.weight_ib, self.factor_size)
        [ic_i, ic_f, ic_o, ic_c] = split_tensor2d(
            self.weight_ic, self.factor_size)
        [b_ii, b_if, b_io, b_ic] = split_tensor1d(
            self.bias_ih, self.hidden_size)

        tmp1_i = (wemb_input @ ia_i)
        tmp1_f = (wemb_input @ ia_f)
        tmp1_o = (wemb_input @ ia_o)
        tmp1_c = (wemb_input @ ia_c)

        tmp2_i = (semantic_input @ ib_i).unsqueeze(0)
        tmp2_f = (semantic_input @ ib_f).unsqueeze(0)
        tmp2_o = (semantic_input @ ib_o).unsqueeze(0)
        tmp2_c = (semantic_input @ ib_c).unsqueeze(0)

        state_below_i = ((tmp1_i * tmp2_i) @ ic_i.t()) + b_ii
        state_below_f = ((tmp1_f * tmp2_f) @ ic_f.t()) + b_if
        state_below_o = ((tmp1_o * tmp2_o) @ ic_o.t()) + b_io
        state_below_c = ((tmp1_c * tmp2_c) @ ic_c.t()) + b_ic

        x_i = state_below_i.squeeze(0)
        x_f = state_below_f.squeeze(0)
        x_o = state_below_o.squeeze(0)
        x_c = state_below_c.squeeze(0)

        if hx is None:
            hx = wemb_input.new_zeros(wemb_input.size(
                0), self.hidden_size, requires_grad=False)
            hx = (hx, hx)

        self.check_forward_hidden(x_i, hx[0], '[0]')
        self.check_forward_hidden(x_i, hx[1], '[1]')

        self.check_forward_hidden(x_f, hx[0], '[0]')
        self.check_forward_hidden(x_f, hx[1], '[1]')

        self.check_forward_hidden(x_o, hx[0], '[0]')
        self.check_forward_hidden(x_o, hx[1], '[1]')

        self.check_forward_hidden(x_c, hx[0], '[0]')
        self.check_forward_hidden(x_c, hx[1], '[1]')

        return self.recurrent_step(x_i, x_f, x_o, x_c, semantic_input, hx)

    def recurrent_step(self, x_i, x_f, x_o, x_c, semantic_input, hx):
        h_, c_ = hx

        [ha_i, ha_f, ha_o, ha_c] = split_tensor2d(
            self.weight_ha, self.factor_size)
        [hb_i, hb_f, hb_o, hb_c] = split_tensor2d(
            self.weight_hb, self.factor_size)
        [hc_i, hc_f, hc_o, hc_c] = split_tensor2d(
            self.weight_hc, self.factor_size)
        [b_hi, b_hf, b_ho, b_hc] = split_tensor1d(
            self.bias_hh, self.hidden_size)

        preact_i = (h_ @ ha_i) * (semantic_input @ hb_i)
        preact_i = (preact_i @ hc_i.t()) + x_i + b_hi

        preact_f = (h_ @ ha_f) * (semantic_input @ hb_f)
        preact_f = (preact_f @ hc_f.t()) + x_f + b_hf

        preact_o = (h_ @ ha_o) * (semantic_input @ hb_o)
        preact_o = (preact_o @ hc_o.t()) + x_o + b_ho

        preact_c = (h_ @ ha_c) * (semantic_input @ hb_c)
        preact_c = (preact_c @ hc_c.t()) + x_c + b_hc

        i = torch.sigmoid(preact_i)
        f = torch.sigmoid(preact_f)
        o = torch.sigmoid(preact_o)
        c = torch.tanh(preact_c)

        c = f * c_ + i * c
        h = o * torch.tanh(c)

        return h, c
